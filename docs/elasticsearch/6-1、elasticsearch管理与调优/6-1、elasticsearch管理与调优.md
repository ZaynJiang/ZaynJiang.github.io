## 1. 开头

​	前面介绍了elasticsearch原理和使用相关的内容，在生产环境如何比较科学的进行容量规划、部署、调优、排查问题呢，业界和官方也对相关的问题进行总结，我这边也结合自己的经验对这些使用elasticsearch经常遇到的问题进行了一下总结。主要包括三大模块：

* **部署模式**
* **容量规划与调优**
* **问题诊断**

## 2. 部署模式

### 2.1. 节点类型

#### 2.1.1.  节点分类

elasticsearch有多种类型的节点，在前面概述和核心也已经介绍过了。在这里可以重新回顾下。

elasticsearch的部署节点类型如下：

* **Master eligible**

  * 主节点及其候选节点，负责集群状态(cluster state)的管理

  * 配置项：node.master，默认为true

* **data**

  * 数据节点，负责数据存储及处理客户端请求

  * 配置项：node.data，默认为true

* **Ingest**

  * ingest节点，负责数据处理，脚本执行

  * 配置项：node.ingest，默认为true

* **Coordinating**

  * 协调节点

  * 配置项：设置上面三个参数全部为false，那么它就是一个纯协调节点

* **machine learning**

  ​	机器学习节点，收费属于x-pack

#### 2.1.2.  节点推荐配置

在生产环境部署推荐配置整体思路就是：**尽量是一个节点只承担一个角色**。

因为不同的节点所需要的计算机资源都不一样。职责分离后可以按需扩展互不影响

* **Master**

  资源要求：中高CPU；中高内存；中低磁盘

  * 一般在生产环境中配置 3 台
  * 一个集群只有 1 台活跃的主节点，负责分片管理，索引创建，集群管理等操作

* **data**

  资源要求：CPU、内存、磁盘要求都高

* **ingest**

  资源要求：高配置 CPU;中等配置的RAM; 低配置的磁盘

* **Coordinating**

  资源要求：一般中高CPU；中高内存；低磁盘

  协调节点扮演者负载均衡、结果的聚合，在大型的es集群中条件允许可以使用高配的cpu和内存。因为如果客户端发起了深度分页等请求可能会导致oom，这个在之前也有过分析。

**注意：如果和数据节点或者 Coordinate 节点混合部署，数据节点本来相对有比较大的内存占用**

**，而Coordinate 节点有时候可能会有开销很高的查询导致 OOM，这些甚至都有可能影响 Master 节点，导致集群的不稳定。**

### 2.2. 架构模式

#### 2.2.1. 基础版部署

![](普通部署图.png) 

这是一个基础版的职责分离的部署架构：比如当磁盘容量无法满足需求时，可以增加数据节点； 磁盘读写压力大时，增加数据节点。但是如果大量的聚合查询等操作，这种架构不太适合了。

#### 2.2.2. 水平扩展部署

![](协调节点扩展部署图.png) 

当系统中有大量的复杂查询或者聚合时候，我们可增加 Coordinating 节点，增加查询的性能，这里增加了负载均衡层，通过负载均衡扩展时应用程序无感知

#### 2.2.3. 读写分离

![](读写分离扩展部署图.png) 

这样部署部署相互影响，写入多的话，多部署ingetst节点，读的时候聚合查询较多可以多部署协调节点，存储数据量大，可以适当对数据节点进行调优。

#### 2.2.4. 冷热分离

我们知道数据有冷热之分，比如写入频繁的日志数据，近期的索引将会频繁写入。es根据数据这些特征引入了hot节点和warm节点。

* hot节点

  使用ssd，该节点上的索引不断的有新文档写入和查询，对cpu、io的要求较高。

* warm节点

  可以使用HDD，上面的索引不会有写入，查询较少。上面只保存只读索引或者旧索引，使用大容量便宜的机械硬盘  

![](冷热分离架构.png) 

配置步骤：

* 在elasticsearch节点启动的时候，在elasticsearch.yml配置文件node.attr中指定当前的节点是hot还是warm。

  如：node.attr.testNodeType=hot

* 通过GET/_cat/nodeattrs?v查看所有的节点的状态

  ![](get查看节点状态.png) 

* 创建索引时指定在何种类型的节点上

  使用属性："index.routing.allocation.require.testNodeType":"hot"即可

* 也可以在已有的索引上使用上述属性，它会将索引的数据迁移到hot节点上

  

#### 2.2.5. 异地多活

针对多机房灾备，elasticsearch业界有多种不同的通用解决方案：

* **跨机房部署集群**

  一个集群中的节点分布在不同的机房

  * 优点：部署简单，一致性高。
  * 缺点：但是对网络带宽和延迟要求较高，仅适用于同城灾备，可能导致可能由于机房间网络中断造成不可用。

* **应用双写**

  应用程序同时将数据写入两个集群

  * 优点：应用端灵活可控

  * 缺点：但是一致性差、延迟高、集群故障时数据会丢失

* **借助消息队列实现双写**

  应用程序先将数据写入消息队列，然后由下游的消费者消费并写入集群

  * 优点：这种方案数据可靠性高，不易丢失

  * 缺点：引入额外的消息队列组件，维护成本高，开发难度大、延迟高，需要保证消息中间件的高可用。

* **CCR 跨集群复制**

  Elasticsearch 官方的跨集群复制功能，基于文档操作实现订阅复制

  * 优点：一致性高、设置简单、延迟低、提供完善的 API ，并且可以监控同步进度，整体有保障。
  * 缺点：白金功能，会员独享；集群之间拉取数据可能会增加额外的负载并影响原有集群本身的磁盘和网络性能

* **定期快照**

  定期将索引备份到外部存储，如hdfs等设备

  * 优点：操作简单，无技术成本

  * 缺点：但是需要通过快照将数据恢复到新集群中，恢复时间长，数据不是实时备份，可能丢失数据

* **极限网关**

  写请求交给网关，网关实时写入主集群，然后异步写备集群

  * 优点：无缝透明，应用程序无需任何调整、网关自动处理故障情况、一致性高，通过校验任务确保数据完全一致
  * 对网关的要求较高

如下是基于**CCR 跨集群复制**的部署架构，因为篇幅有限，异地多活又是一个很大的话题，其它方案和其细节可以查阅相关资料。

![](多机房灾备部署图.png) 



## 3. 容量规划与调优

### 3.1. 分片数量

​	我们知道当es集群的节点数大于索引的分片数时，集群将无法通过水平扩展提升集群的性能。而分片数过多，对于聚合查询以及集群的元数据管理也都有影响。总结下来分片数量较多具体优缺点为：

* 分片数量较多优点：

  * 新数据节点加入后，分片会自动分配扩展性强
  * 数据写入分散到不同节点，减少每个节点的压力

* 缺点：

  * 每个分片就是一个lucene索引，这个索引会占用较多的机器资源，造成额外的开销

  * 搜索时，需要到每个分片获取数据

  * master节点维护分片、索引的元信息，造成master节点管理成本过高。

    通常建议一个集群总分片数小于10w

如何设计分片的数量呢？一个分片保持多大的数据量比较合适呢？

#### 3.1.1.  主分片

我们需要根据使用场景来设置：

* 日志类，其特点为：写入频繁，查询较少

  单个分片不要大于50G

* 搜索类，其特点为：写入较少，查询频繁

  单个分片不超过20G

解释：

#### 3.1.2.  副本分片

### 3.2. 集群配置

#### 3.2.1. jvm

* xms和xmx设置成一样，避免heap resize时卡顿

* xmx不要超过物理内存的50%

  因为es的lucene写入强依赖于操作系统缓存，需要预留加多的空间给操作系统

* 最大内存不超过32G，但是也不要太小

  堆太小会导致频繁的小延迟峰值，并因不断的垃圾收集暂停而降低吞吐量

  如果堆太大，应用程序将容易出现来自全堆垃圾回收的罕见长延迟峰值

  将堆限制为略小于 32 GB可以使用jvm的指针压缩技术增强性能

* jvm使用server模式

* 推荐采用g1垃圾回收器

* 关闭jvm swapping

  关闭交换分区的方法是：

  ```
  //将/etc/fstab 文件中包含swap的行注释掉
  sed -i '/swap/s/^/#/' /etc/fstabswapoff -a
  ```

* 其它的配置尽量不要修改，使用默认的配置。

这里是官方的jvm推荐配置链接：https://www.elastic.co/cn/blog/a-heap-of-trouble

#### 3.2.2. 集群节点数

es的节点提供查询的时候使用较多的内存来存储查询缓存，es的lucene写入到磁盘也会先缓存在内存中，我们开启设计这个es节点时需要根据每个节点的存储数据量来进行判断。这里有一个流行的推荐比例配置：

* 搜索类比例：1:16(内存:节点要存储的数据)
* 日志类比例：1:48-1:96(内存:节点要存储的数据)

示例：

有一个业务的数据量预估实际有1T，我们把副本设置1个，那么es中总数据量为2T。

* 如果业务偏向于搜索

  每个节点31*16=496G。在加上其它的预留空间，每个节点有400G的存储空间。2T/400G，则需要5个es存储节点。

* 如果业务偏向于写入日志型

  每个节点31*50=1550G，就只需要2个节点即可

这里31G表示的是jvm设置不超过32g否则不会使用java的指针压缩优化了。

#### 3.2.3. 网络

* 当个集群不要跨机房部署
* 如果有多块网卡，可以将tranport和http绑定到不同的网卡上，可以起到隔离的作用
* 使用负载聚合到协调节点和ingest node节点

#### 3.2.4.  磁盘

前面也提到过，数据节点推荐使用ssd

### 3.3. 通用设置

* 关闭动态索引创建功能
* 通过模板设置白名单

### 3.3. 写入和查询优化

#### 3.3.1. 写入优化

写入的目标在于增大写入的吞吐量，这里主要从两个方面进行优化：

* 客户端：

  * 通过压测确定每次写入的文档数量。一般情况：
    * 单个bulk请求数据两不要太大，官方建议5-15mb
    * 写入请求超时时间建议60s以上
    * 写入尽量不要一直写入同一节点，轮询达到不同节点。
  * 进行多线程写入，最好的情况时动态调整，如果http429，此时可以少写入点，不是可以多写点

* server：

  总体目标尽可能压榨服务器资源，提高吞吐量

  * 使用好的硬件，观察cpu、ioblock、内存是否有瓶颈
  * 观察jvm堆栈，垃圾回收情况是否存在耗时较长的gc。
  * 观察写入的分配和节点是否负载均衡
  * 调整bulk线程池和队列的大小，一般不用调整，它是根据现有核数和内存自动算出来的，酌情调整。一般线程数配置为CPU核心数+1，队列也不要太大，否则gc比较频繁。
  * 可靠性要求不高，可以副本设置为0
  * 磁盘io肯定没有内存快，可以在允许的情况refresh调整间隔大一点
  * flush阈值适当调大、落盘异步化、flush频率调高。这些都能减少写入资源的占用，提升写入吞吐能力。但是对容灾能力有损害。

* 索引设置优化

  * 减少不必要的分词，从而降低cpu和磁盘的开销
  * 只需要聚合不需要搜索，index设置成false
  * 不需要算分，可以将norms设置成false
  * 不要对字符串使用默认的dynmic mapping。会自动分词产生不必要的开销
  * index_options控制在创建倒排索引时，哪些内容会被条件到倒排索引中，只添加有用的，这样能很大减少cpu的开销
  * 关闭_source，减少io操作。但是source字段用来存储文档的原始信息，如果我们以后可能reindex，那就必须要有这个字段 

这里可以针对myindex索引优化的示例：

```
    PUT myindex {
    	"settings": {
    		"index" :{
    			"refresh_interval" : "30s","number_of_shards" :"2"
    		},
    		"routing": {
    			"allocation": {
    				"total_shards_per_node" :"3"
    		    }
    		},
    		"translog" :{
    			"sync_interval" : "30s",
    			"durability" : "async"
    		},
    		number_of_replicas" : 0
    	}
    	"mappings": {
    		"dynamic" : false,
    		"properties" :{}
    	}
    }
```

* 设置30s refresh，降低lucene生成频次，资源占用降低提升写入性能，但是损耗实时性
* total_shards_per_node控制分片集中到某一节点，避免热点问题
* translong落盘异步化，提升性能，损耗灾备能力
* dynamic设置false，避免生成多余的分词字段，需要自行确定映射

#### 3.3.2. 查询优化

首先有几个原则我们需要清楚：

* elasticsearch不是关系型数据库，即使elasticsearch支持嵌套、父子查询，但是会严重损耗elasticsearch的性能，速度也很慢。

* 尽量先将数据计算出来放到索引字段中，不要查询的时候再通过es的脚本来进行计算。

* 尽量利用filter的缓存来查询

  ![](filter查询.jpg) 

* 设计上不要深度分页查询，否则可能会使得jvm内存爆满

* 可以通过profile、explain工具来分析慢查询的原因

* 严禁*号通配符为开头的关键字查询，我们可以利用不同的分词器进行模糊查询。

* 分片数优化，避免每次查询访问每一个分片，可以借助路由字段进行查询

* 需要控制单个分片的大小

  这个上面有提到：查询类：20GB以内；日志类：50G以内

* 读但是不写入文档的索引进行lucene段进行强制合并。

* 优化数据模型、数据规模、查询语句

## 4. 问题诊断

### 4.1. 索引健康状态 

#### 4.1.1. 监控状态 

* 绿色代表集群的索引的所有分片（主分片和副本分片）正常分配了
* 红色代表至少一个主分片没有分配
* 黄色代表至少一个副本没有分配

我们可以通过health相关的api进行查看

```
//集群的状态（检查节点数量）
GET _cluster/health
//所有索引的健康状态 （查看有问题的索引）
GET _cluster/health?level=indices
//单个索引的健康状态（查看具体的索引）
GET _cluster/health/my_index
//分片级的索引
GET_cluster/health?level=shards
//返回第一个未分配Shard 的原因
GET _cluster/allocation/explain
```

#### 4.1.2. 常见原因

* 集群变红

  * 创建索引失败，我们可以通过Allocation Explain API查看，会返回解释信息
  * 集群重启阶段，短暂变红
  * 打开一个之前关闭的索引
  * 有节点离线。通常只需要重启离线的节点使其回来即可
  * 一个节点离开集群，有索引被删除，离开的节点又回来了。会导致出现红色，产生了dangling索引
  * 磁盘空间限制，分片规则（Shard Filtering）引发的，需要调整规则或者增加节点

  官方文档给出了详细的未分配分片的可能原因:https://www.elastic.co/guide/en/elasticsearch/reference/7.1/cat-shards.html

* 集群变黄
  * 无法创建副本，因为副本能和它的主分配在一个节点上，可能副本数过大或者节点数过少导致

### 4.2. 慢查询

#### 4.2.1. profile api定位慢查询

在查询条件中设置profile为true的参数，将会显示查询经历的细节

```
GET trace_segment_record_202204291430/_search
{
  "query": {
     "match": {
       "serviceIp" : "xxxxx"
     }
  },
  "profile": true
}
```

其结果为：

![](profile返回结果1.png) 

这里会返回一个shards列表。其中：

* id表示，【nodeId】【shardId】

* query

  主要包含了如下信息：

  * query_type

    展示了哪种类型的查询被触发。

  * lucene

    显示启动的lucene方法

  * time

    执行lucene查询小号的时间

  * breakdown

    里面包含了lucene查询的一些细节参数

* rewrite_time

  多个关键字会分解创建个别查询，这个分解过程花费的时间。将重写一个或者多个组合查询的时间被称为”重写时间“

* collector

  在Lucene 中，收集器负责收集原始结果，并对它们进行组合、过滤、排序等处理。这里我们可以根据这个查看收集器里面花费的时间及一些参数。

​	Profile API让我们清楚地看到查询耗时。提供了有关子查询的详细信息，我们可以清楚地知道在哪个环节查询慢，另外返回的结果中，关于Lucene的详细信息也让我们深入了解到ES是如何执行查询的。

#### 4.2.2. 查看慢日志

ES记录了两类慢日志：

* 慢搜索日志

  用来记录哪些查询比较慢，每个节点可以设置不同的阈值。

  之前我们已经详细分析了ES的搜索由两个阶段组成:

  * 查询
  * 取回

  慢搜索日志给出了每个阶段所花费的时间和整个查询内容本身。

  慢搜索日志可以为查询和取回阶段单独设置以时间为单位的阈值，在定义好每个级别的时间后，通过level决定输出哪个级别的日志。

  示例如下

  ```autohotkey
  PUT kibana_sample_data_logs/_settings
  {
    "index.search.slowlog.threshold.query.warn": "100ms",
    "index.search.slowlog.threshold.query.info": "50ms",
    "index.search.slowlog.threshold.query.debug": "10ms",
    "index.search.slowlog.threshold.query.trace": "60ms",
    "index.search.slowlog.threshold.fetch.warn": "100ms",
    "index.search.slowlog.threshold.fetch.info": "50ms",
    "index.search.slowlog.threshold.fetch.debug": "20ms",
    "index.search.slowlog.threshold.fetch.trace": "60ms",
    "index.search.slowlog.level": "debug"
  }
  ```

  ```
  [2030-08-30T11:59:37,786][WARN ][i.s.s.query              ] [node-0] [index6][0] took[78.4micros], took_millis[0], total_hits[0 hits], stats[], search_type[QUERY_THEN_FETCH], total_shards[1], source[{"query":{"match_all":{"boost":1.0}}}], id[MY_USER_ID],
  ```

  参考官方链接：

  https://www.elastic.co/guide/en/elasticsearch/reference/7.17/index-modules-slowlog.html

### 4.3. 节点异常

#### 4.3.1. 节点cpu过高

如果出现节点占用CPU很高，我们需要知道CPU在运行什么任务，一般通过线程堆栈来查看。

这里有两种方式可以查看哪些线程CPU占用率比较高：

* 使用elasticsearch提供的hot_threads api查看
* 使用jstack和top命令查看，针对java应用cpu过高问题的这个是通用做法。

这里推荐使用hot_threads api

```
GET /_nodes/hot_threads
GET /_nodes/<node_id>/hot_threads
```

通过返回的结果可以看到什么线程占用更高，正在做什么操作。

更详细的内容可以参考官网：https://www.elastic.co/guide/en/elasticsearch/reference/7.17/cluster-nodes-hot-threads.html

#### 4.3.2. 内存使用率过高

### 4.4. 常用工具

#### 4.4.1. iostat命令

我们这里按照1s的频率输出磁盘信息

![](iostate统计结果.png) 

* iops

  由r/s(每秒读次数）和 w/s(每秒写次数）组成。

* await

  平均IO等待时间，包括硬件处理IO的时间和在队列中的等待时间。

* %util

  设备的繁忙比，是设备执行的I/O时间与所经过的时间百分比。当值接近100%时设备产生饱和。在设备具有并行处理能力的情况下，util达到100%不代表设备没有余力处理更多I/O请求。

如果想查看和进程关联的信息，可以使用pidstat、iotop

#### 4.4.2. sar -B

当系统物理内存不足时，系统回收效率对部署的es节点的性能有较大的影响。我们可以通过sar -B来观察内存分页信息

![](sarB内存命令结果.png) 

* pgfree/s

  每秒被放入空闲列表中的页数，如果其他进程需要内存，则这些页可以被分页( paged out）。

* pgscank/s

  每秒被kswapd守护进程扫描的页数。

* pgscand/s

  每秒被直接扫描的页数。

* pgsteal/s

  为了满足内存需求，系统每秒从缓存（pagecache和 swapcache）回收的页面数。

* %vmeff

  代表页面回收效率

  计算方式为pgsteal/(pgscand + pgscank)。

  过低表明虚拟内存存在问题，如果在采样周期内没有发生页面扫描，则该值为0或接近100。

我们可以重点关注vmeff，当为0和接近100时说明内存够用，其它情况页面回收效率过低，内存也不够。

**PS：我们需要关闭内存交换，内存交换会严重损害性能**。



#### 4.4.3.  cpu

#### 4.4.4.  网络

* sar -n DEV 1

  ![](网络sar结果.png) 

* netstat

  

## 5. 总结
