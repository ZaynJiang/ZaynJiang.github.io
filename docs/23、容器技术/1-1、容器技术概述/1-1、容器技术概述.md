## 1. 概述

容器其实是一种沙盒技术，沙盒就是能够像一个集装箱一样，把你的应用“装”起来的技术。这样，应用与应用之间，就因为有了边界而不至于相互干扰

## 2. 容器的隔离

### 2.1. 进程

​	**容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”**

​	对于 Docker 等大多数 Linux 容器来说，**Cgroups 技术**是用来制造约束的主要手段，而**Namespace 技术**则是用来修改进程视图的主要方法

```
$ docker run -it busybox /bin/sh
```

创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。本质上理解，namespace 和 cgroup 是内核特性，容器本质上就是一个加了限定参数的进程

**容器，其实是一种特殊的进程而已**

### 2.2. Linux Cgroups

Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等

Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了

#### 2.2.1. 使用命令查看可限制资源的种类：

```
$ mount -t cgroup 
cpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)
cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)
cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)
blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)
memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)
...
```

#### 2.2.2. cpu限制示例

对 CPU 子系统来说，我们就可以看到如下几个配置文件

```
$ ls /sys/fs/cgroup/cpu
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
```

输出里注意到 cfs_period 和 cfs_quota 这样的关键词

可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间

限制示例：

* 在对应的子系统下面创建一个目录，这个目录就成为控制组

* 操作系统会在你新创建的 container 目录下，自动生成该子系统对应的资源限制文件

* 修改CPU这些文件的内容来设置限制，如向 container 组里的 cfs_quota 文件写入 20 ms

* 我们把被限制的进程的 PID 写入 container 组里的 tasks 文件，上面的设置就会对该进程生效了

  ```
  /sys/fs/cgroup/cpu/container/tasks 
  ```

*  top 指令查看一下,该进程计算机的 CPU 使用率立刻降到了 20%
* 除 CPU 子系统外，Cgroups 的每一项子系统都有其独有的资源限制能力
  - blkio，为块设备设定I/O 限制，一般用于磁盘等设备；
  - cpuset，为进程分配单独的 CPU 核和对应的内存节点；
  - memory，为进程设定内存使用的限制

#### 2.2.2. 缺陷

* 不能运行多个应用

​		在一个容器中，没办法同时运行两个不同的应用，除非你能事先找到一个公共的 PID=1 的程序来充当两个不同应用的父进程，这也		是为什么很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程

* 信息不一致

  Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题

  Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源

  因此，如果在容器里执行 top 指令，显示宿主机的 CPU 和内存数据，而不是当前容器的数据

解决方案：

* top 是从 /prof/stats 目录下获取数据，所以道理上来讲，容器不挂载宿主机的该目录就可以了。lxcfs就是来实现这个功能的，做法是把宿主机的 /var/lib/lxcfs/proc/memoinfo 文件挂载到Docker容器的/proc/meminfo位置后。容器中进程读取相应文件内容时，lxcfs的FUSE实现会从容器对应的Cgroup中读取正确的内存限制。从而使得应用获得正确的资源约束设定。kubernetes环境下，也能用，以ds 方式运行 lxcfs ，自动给容器注入争取的 proc 信息
* 用的是vanilla kubernetes，遇到的主要挑战就是性能损失和多租户隔离问题，性能损失目前没想到好办法，可能的方案是用ipvs 替换iptables ，以及用 RPC 替换 rest。多租户隔离也没有很好的方法，现在是让不同的namespace调度到不同的物理机上。也许 rancher和openshift已经多租户隔离

## 3. 容器的隔离

